{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./data/구석구석_서울크롤링_4057.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 컬럼 선별\n",
    "use_col = ['장소명', '상세설명','한줄설명', '리뷰','대표메뉴','취급메뉴', '주소']\n",
    "\n",
    "# 전체 컬럼 중 사용할 컬럼이 아니면 제거\n",
    "df.drop(set(df.columns) - set(use_col), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소 결측치 제거\n",
    "df.drop(index=2665, inplace=True)\n",
    "\n",
    "# index 재설정\n",
    "df.reset_index(drop='index', inplace=True)\n",
    "\n",
    "# null 값 공백으로 치환\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import re\n",
    "ko = Komoran()\n",
    "\n",
    "for col in use_col[1:]:\n",
    "    for row, text in enumerate(df[col]):\n",
    "        # 이모지, 특수문자 제거\n",
    "        token = ko.nouns(re.sub('[^A-Za-z0-9가-힣]', ' ', text))\n",
    "\n",
    "        # 정제된 토큰들로 다시 문장화\n",
    "        df.loc[row, col] = \" \".join(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 컬럼들의 모든 text를 이어 붙일 '정보' 컬럼 생성\n",
    "df['정보'] = df['장소명'] + \" \"\n",
    "\n",
    "for i in use_col[1:] :\n",
    "    df.정보 += df[i]\n",
    "\n",
    "# 장소명과 정보 컬럼을 제외한 나머지 컬럼 삭제\n",
    "df.drop(use_col[1:], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어\n",
    "stop_word = [\n",
    "    ' ',',','.','등','수','이요','요','번','앞','곳','집','류','모','봉','돌','호선','객','부','콩','겸','그','위','계','무','안','눈','방','이','팅',\n",
    "    '비','통','석','개','세','순','외','점','전','것','두','나','옥','내','역','과','뿐','이류','찰','더','여','년','로','층','차','종','배','중','몽',\n",
    "    '도','날','널','때','꼭','및','볼','후','룸','의','실','또','제','온','를','터','인','탕','총','각','명','저','리','처','존','뜻','이자','움','입',\n",
    "    '게','좀','데','기','만','용','초','몸','핫','거','넉','끼','단','접','호','창','난','칸','스','또한','듯','때문','린','오','시','은','함','적','샷',\n",
    "    '이후','마치','가도','원','임','이제','얼마','밍','재','란','송','거나','구','중이','늘','감','앤','변','목','대해','근대','운','널리','곳도','가끔',\n",
    "    '주','걸','장','상','이외','통해','얼','유','사','도량','갓','너','고기구','깃'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "for i in range(len(df)) :\n",
    "    temp = [word for word in df.정보[i].split(' ') if word not in stop_word]\n",
    "    df.loc[i, '정보'] = ' '.join(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(df['정보'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 모델 저장\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자의 입력문장을 통한 코사인 유사도 계산\n",
    "def user_input_to_cosine_sim(model, query) :\n",
    "    query = ' '.join(ko.nouns(query))\n",
    "    query_tfidf = model.transform([query])\n",
    "    cosine_sim = cosine_similarity(query_tfidf, tfidf_matrix).reshape(-1)\n",
    "    return cosine_sim\n",
    "\n",
    "# 장소명을 입력받아 그 장소명의 정보 추출\n",
    "def searchByName(place_name) :\n",
    "    # 찾을 정보의 df\n",
    "    find_df = pd.read_csv(\"./data/구석구석_서울_크롤링_imageurl.csv\")\n",
    "    json_col = [\"장소명\", \"주소\", \"상세설명\", \"문의 및 안내\", \"사진주소\"]\n",
    "\n",
    "    # temp_dict = find_df.loc[find_df.장소명 == place_name, json_col].fillna(\"정보 없음\").iloc[0].to_dict()\n",
    "    temp_df = find_df.loc[(find_df.장소명 == place_name), json_col].fillna(\"정보 없음\")\n",
    "    temp_df.columns = [\"name\", \"address\", \"description\", \"inquieries\", \"imageName\"]\n",
    "\n",
    "    return temp_df.iloc[0].to_dict()\n",
    "\n",
    "# 저장된 모델 불러오기\n",
    "with open('./tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# 사용자가 입력한 문장\n",
    "input_sentence = \"강남구 갈비집\"\n",
    "\n",
    "\n",
    "result_cosine_similarity = user_input_to_cosine_sim(loaded_model, input_sentence)\n",
    "top_index = np.argsort(result_cosine_similarity)[::-1]\n",
    "\n",
    "result_arr = []\n",
    "\n",
    "for row in top_index[:10]:\n",
    "    name = df.loc[row, '장소명']\n",
    "    result_arr.append(searchByName(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df의 모든 정보를 return\n",
    "def find_all_info() :\n",
    "    find_df = pd.read_csv(\"./data/구석구석_서울_크롤링_imageurl.csv\")\n",
    "    json_col = [\"장소명\", \"주소\", \"상세설명\", \"문의 및 안내\", \"사진주소\"]\n",
    "\n",
    "    temp_df = find_df.loc[:, json_col].fillna(\"정보 없음\")\n",
    "    temp_df.columns = [\"name\", \"address\", \"description\", \"inquiries\", \"imageName\"]\n",
    "\n",
    "    result_arr = []\n",
    "    for i in range(len(temp_df)) :\n",
    "        result_arr.append(temp_df.iloc[i,:].to_dict())\n",
    "\n",
    "    return result_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
